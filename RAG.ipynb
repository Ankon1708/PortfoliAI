{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b23b98d-eb17-4f2a-896b-1f81e2b40cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Keys import my_lang_api_key, my_google_api_key\n",
    "import os\n",
    "os.environ[\"GOOGLE_API_KEY\"] = my_google_api_key\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGSMITH_PROJECT']=\"PortfoliAI_v1\"\n",
    "os.environ['LANGCHAIN_API_KEY'] = my_lang_api_key\n",
    "\n",
    "import langchain\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_google_genai.embeddings import GoogleGenerativeAIEmbeddings\n",
    "from langchain_core.runnables.base import RunnableEach\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate\n",
    "from IPython.display import Markdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ba28e99-6606-4036-8d5a-c8714dbd216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Keys import my_lang_api_key, my_google_api_key\n",
    "import os\n",
    "os.environ[\"GOOGLE_API_KEY\"] = my_google_api_key\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGSMITH_PROJECT']=\"PortfoliAI_v1\"\n",
    "os.environ['LANGCHAIN_API_KEY'] = my_lang_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "032d2c98-b803-4b91-915e-386096f1b370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from markdown import markdown\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ff9dae78-84db-4fff-a512-3a538e7b1316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain_core.runnables.base as runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7eba73f2-63ba-4eef-bd4e-626a0f51c9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.base import RunnableEach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7018533-82d8-4b0c-9a82-73f184aadd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a63373b7-ab7c-43ee-bda6-95c0475f03ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0.5,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4904b8f9-5670-47f7-afff-6c880b193555",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.chains.qa_with_sources.loading import load_qa_with_sources_chain\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef657135-7f62-4390-b616-4e466d76a57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai.embeddings import GoogleGenerativeAIEmbeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdb175cd-a42c-4a54-94b2-d5239d04f88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db=FAISS.load_local(\"faiss_vector_db\",embeddings,allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d296d943-02b6-484c-a789-1b282c1c701d",
   "metadata": {},
   "source": [
    "## RetrievalQAWithSourcesChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00101f65-2d18-4e62-ab34-ad5f4cf899a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RetrievalQAWithSourcesChain.from_llm(llm=llm, retriever=vector_db.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fdbc844-a60c-435e-8f28-8c54541a2b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_query=\"Describe his projects that involve python.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6690e67-0718-483b-b4a2-bb33b495c57a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'C://Users//ASUS//Documents//Python Scripts//LnE Langchain//RAG Documents//Ankon Bhowmick Resume.docx'}, page_content='Estimating Public Opinion on Gun Legislation using MRP:\\n\\nEstimated public opinion on a ban on assault rifles in the US at the state level using a singular national survey.\\n\\nCollected survey data and population data and conducted data cleaning, transformation, and data matching to created input dataset and poststratification frame respectively using the Python packages Pandas and NumPy.\\n\\nModelled hierarchical relationships between individual-level and group-level predictors using rstanarm package in R and analysed interactions and state-level predictors using posterior distributions.\\n\\nValidated model performance using split sample validation and disaggregation for varying MRP sample sizes. Evaluated model performance using MAE, Correlation, and WAIC.\\n\\nPoststratified for final state-wise predictions of percentage opposition to a ban on assault rifles. Presented results using matplotlib in Python and ggplot2 in R.\\n\\nTime Series Forecasting:'),\n",
       " Document(metadata={'source': 'C://Users//ASUS//Documents//Python Scripts//LnE Langchain//RAG Documents//Ankon Bhowmick Resume.docx'}, page_content='Using Markov Chain Monte Carlo to Predict Average Resting Heart Rate:\\n\\nImplemented Markov Chain Monte Carlo (MCMC) model for analysing resting heart rate data. Collected personal heart rate data over a period of 124 days using a Samsung fitness tracker.\\n\\nFocused on the parameter of interest, µ, utilizing the Metropolis-Hastings Algorithm.\\n\\nConstructed a posterior distribution and estimated the mean of Daily Average Resting Heart Rate (DARHR).\\n\\nBuilt a categorical probability distribution for defined health fitness levels on the basis of heart rate.\\n\\nBuilding a Quantitative Momentum Investing Model:\\n\\nDeveloped an investment model constructing portfolios with a Quantitative Momentum Investing strategy on NIFTY50.\\n\\nEstablished a data pipeline using pandas and NumPy for cleaning, transforming, and integrating data from individual company data files.\\n\\nProcessed data through the investment model to create portfolios.\\n\\nUnderstanding Players’ Environmental Perception in a Game Environment'),\n",
       " Document(metadata={'source': 'C://Users//ASUS//Documents//Python Scripts//LnE Langchain//RAG Documents//Ankon Bhowmick Resume.docx'}, page_content='Image classification using CNN and Image Captioning using RNN:\\n\\nConstructed basic NN and CNN classification models using TensorFlow and PyTorch. Trained models on TinyImageNet30 dataset, which contained 450 images each for 30 classes of images.\\n\\nConfigured the best performing model and tackled overfitting by using data augmentation, dropout, hyper-parameter tuning and optimising evaluation metrics such as accuracy, loss, and ROC-AUC curves.\\n\\nImplemented transfer learning by fine-tuning previously designed and trained model on CIFAR10 dataset, explored effect of freezing of layers of model on fine-tuning.\\n\\nBuilt an encoder-decoder architecture-based model to generate captions for images. Constructed an encoder network to convert images into feature vectors, and a decoder network to create captions using encoded vectors.\\n\\nE-commerce Insights and Analysis Project'),\n",
       " Document(metadata={'source': 'C://Users//ASUS//Documents//Python Scripts//LnE Langchain//RAG Documents//Ankon Bhowmick Resume.docx'}, page_content='Financial Engineering: Option Pricing, Stochastic Calculus, Portfolio Theory\\n\\nAcademic Projects\\n\\nPredicting the Course of the Russo-Ukrainian War:\\n\\nCollected data through web scraping using Selenium and Beautiful Soup packages in Python. Scraped over 1300 articles of the Russo-Georgian war and 32000 articles of the Russo-Ukrainian war by Russian state news agency TASS.\\n\\nPreprocessed articles using tokenisation to created model suitable input. Stored data in the form of Tensor datasets and then Pytorch dataloaders.\\n\\nLeveraged Hugging Face’s Transformers library to fine-tune BERT, optimizing hyperparameters for enhanced model accuracy in text classification of news articles into war-intensity categories. Trained BERT on news articles from the 2008 Russo-Georgian war.\\n\\n\\n\\nPredicted war-intensity for articles of the Russo-Ukrainian war to create a fabricated timeline for the purpose of analysing and understanding Russian war actions.'),\n",
       " Document(metadata={'source': 'C://Users//ASUS//Documents//Python Scripts//LnE Langchain//RAG Documents//CL.docx'}, page_content='taught me to approach problem-solving with a data-driven mindset. I am also experienced in data visualization, having worked with tools like Tableau, matplotlib, and ggplot2 to present complex findings to non-technical stakeholders.')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_db.similarity_search(query=my_query,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71384a5d-8dae-4c84-9124-f73fc6b2b55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer=chain.invoke({\"question\": my_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e0f2f19-c8d6-4330-9481-5137e5dc4f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "His projects involving Python include:\n",
      "\n",
      "*   **Data Analysis and Presentation**: He collected survey and population data, performing data cleaning, transformation, and matching using Python packages Pandas and NumPy. He presented the results using matplotlib in Python.\n",
      "*   **Quantitative Momentum Investing Model**: He established a data pipeline for cleaning, transforming, and integrating data from individual company files using pandas and NumPy.\n",
      "*   **Image Classification and Captioning**: He constructed basic Neural Network (NN) and Convolutional Neural Network (CNN) classification models using TensorFlow and PyTorch. He also built an encoder-decoder architecture-based model to generate captions for images, using an encoder network to convert images into feature vectors and a decoder network to create captions.\n",
      "*   **Predicting the Course of the Russo-Ukrainian War**: He collected data through web scraping using Selenium and Beautiful Soup packages in Python. He preprocessed articles and stored data in PyTorch dataloaders. He leveraged Hugging Face’s Transformers library to fine-tune BERT for text classification of news articles.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(answer['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df27ceb-9e02-4a90-9c29-649c238d3ffd",
   "metadata": {},
   "source": [
    "## Prompts and Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "681299dd-b45a-49a3-b6c6-2140408c3ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "242a2130-4674-4b75-b60a-8b3dd1ca9a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = SystemMessagePromptTemplate.from_template(\n",
    "    \"You are an AI assistant that answers queries about a candidate.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cdcfb7a-7855-46f1-964e-37f919244778",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_rag_human = HumanMessagePromptTemplate.from_template(\n",
    "    \"\"\"You are tasked with drafting an answer for a question asked regarding a candidate's skills and experience.\n",
    "\n",
    "The answer should only contain information on the candidate in the form of context that has been made available to you, do not falsify any skills or experience. \n",
    "For behavourial questions, use slightly creative vocabulary to best answer them.\n",
    "The context is: {context}\n",
    "The question is: {question}\"\"\",\n",
    "    input_variables=[\"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "443812a9-9c19-40ac-866a-a96062af9e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_rag = ChatPromptTemplate.from_messages([system_prompt, prompt_rag_human])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07f7fede-26be-4fe1-91bb-ff8aae59991f",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=vector_db.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1097625a-a28b-418a-898f-0269e889808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_ret=vector_db.similarity_search(query=\"What ML algorithms does he know?\",k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "edbbe029-e37d-4186-8f94-9088c2fe76b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'C://Users//ASUS//Documents//Python Scripts//LnE Langchain//RAG Documents//Ankon Bhowmick Resume.docx'}, page_content='Certifications\\n\\nData Science Project-Based Learning and Internship Program Using R, Python Programming, And Tableau, StepUp Analytics, Online, (December 2020 - February 2021)\\n\\nMicrosoft Excel (Office 2019): Exam Reference #45320081\\n\\nSkills\\n\\nProgramming Languages: Python, R, SQL\\n\\nPython Libraries: Pandas, NumPy, Matplotlib, Seaborn, Scikit-learn, Transformers, OpenCV, PyTorch, TensorFlow\\n\\nR Libraries: dplyr, ggplot2, caret, glm, rpart, timeSeries, rstanarm\\n\\nML Algorithms: Linear Regression, Logistic Regression, KNN, Decision Trees, Naïve Bayes, K-Means, DBSCAN, Random Forest, PCA, Multi-level Regression\\n\\nDeep Learning: CNN, RNN, LSTM\\n\\nNLP: Text Preprocessing, Embeddings, Vector Database (FAISS), BERT (HuggingFace), GenAI (LangChain)\\n\\nOther Relevant Coursework: Time Series, Business Analytics, Data Structures & Algorithms, Data Mining & Warehousing, Operations Research, Probability & Statistics, Stochastic Processes, Statistical Learning, Linear Algebra')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_ret[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "41c84582-7108-4025-8e0d-a6f20cd135d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "825"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_ret[2].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737db299-1f9c-4743-8f0f-ce3e9eff568d",
   "metadata": {},
   "source": [
    "## Custom RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a13db40c-266a-428c-a136-3c5482ed0592",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt_rag\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f319baf3-c986-4373-aa28-02e538ad0828",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_query='What kind of work has he done in Python?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "30f0d092-5eba-4d22-9acb-dcd31ca023a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer=rag_chain.invoke(my_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a370453e-1078-4cdc-8b15-1c3e04750b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The candidate possesses a robust understanding of various machine learning algorithms, including Linear Regression, Logistic Regression, KNN, Decision Trees, Naïve Bayes, K-Means, DBSCAN, Random Forest, PCA, and Multi-level Regression.\n",
       "\n",
       "Their practical application of these algorithms is evident in several projects:\n",
       "\n",
       "*   **Predictive Modelling:** In a project focused on predicting the success of an ICO, the candidate adeptly utilized **Random Forest Classifier (RFC)** and **Support Vector Classifier (SVC)** models, achieving competitive accuracy scores. They also optimized these models by fine-tuning hyperparameters and rigorously evaluating performance using metrics like precision, recall, F1-score, and ROC-AUC analysis.\n",
       "*   **Deep Learning for Diverse Data Types:** The candidate has a strong command over handling diverse data types, demonstrated through their work with **CNN (Convolutional Neural Networks)** for image classification and **RNN (Recurrent Neural Networks)** for image captioning. They constructed and trained CNN models on datasets like TinyImageNet30 and implemented transfer learning. For image captioning, they built an encoder-decoder architecture using RNNs.\n",
       "*   **Natural Language Processing (NLP):** Their NLP project involved extensive work with unstructured data, where they implemented and fine-tuned the **LLM BERT** for analyzing news articles.\n",
       "*   **Optimization:** The candidate also applied **linear programming** to optimize the allocation of delivery robots, enhancing operational efficiency.\n",
       "*   **General Predictive Models:** They have leveraged machine learning frameworks such as TensorFlow, PyTorch, and scikit-learn to build predictive models and optimize their performance across various academic and personal endeavors."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f65f968-0c75-4918-bc13-95ddf142744a",
   "metadata": {},
   "source": [
    "## Multi-Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37ee3164-4756-42ad-8f74-cf1c32a7a818",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are an AI language model assistant. Your task is to generate five \n",
    "different versions of the given user question to retrieve relevant documents from a vector \n",
    "database. By generating multiple perspectives on the user question, your goal is to help\n",
    "the user overcome some of the limitations of the distance-based similarity search. \n",
    "Provide these alternative questions separated by newlines. Original question: {question}\"\"\"\n",
    "prompt_genq = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "generate_queries = (\n",
    "    prompt_genq\n",
    "    | llm \n",
    "    | StrOutputParser() \n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34abcb01-4142-4180-907f-0ba373f4854e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fa6938-944c-4b13-a5eb-cd2b66f99a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_gen=generate_queries.invoke({'question':'What kind of work has he done in Python?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "575dd7ca-91c6-411c-9d8d-82e1b72ede0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What Python projects has he completed?'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_gen[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532b68da-42e7-4832-a7e2-380a5bce57b8",
   "metadata": {},
   "source": [
    "## Parallel RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf0f0c16-8322-48c1-bb22-081269265f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_rag=(\n",
    "    RunnableEach(bound=rag_chain)\n",
    "    | (lambda x: \"\".join(x))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cef0b6e6-4889-4aea-b155-ecd87f250d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers=parallel_rag.invoke(query_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fbb558a9-881c-44ef-95fc-434fbd41fc77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The candidate has completed several projects utilizing Python and its libraries:\n",
       "\n",
       "*   **Estimating Public Opinion on Gun Legislation using MRP:** This project involved collecting survey and population data, and conducting data cleaning, transformation, and data matching using Python packages like Pandas and NumPy. Results were presented using Matplotlib.\n",
       "*   **Image classification using CNN and Image Captioning using RNN:** For this project, the candidate constructed basic NN and CNN classification models using TensorFlow and PyTorch. An encoder-decoder architecture-based model was built to generate captions for images.\n",
       "*   **Using Markov Chain Monte Carlo to Predict Average Resting Heart Rate:** While the primary algorithm (MCMC) is conceptual, the context mentions data collection and analysis, and given the candidate's Python skills, it's highly probable Python was used for data handling.\n",
       "*   **Building a Quantitative Momentum Investing Model:** This project established a data pipeline using Pandas and NumPy for cleaning, transforming, and integrating data.\n",
       "*   **Predicting the Course of the Russo-Ukrainian War:** This involved collecting data through web scraping using Selenium and Beautiful Soup packages in Python. Data was stored as Tensor datasets and PyTorch dataloaders. The project leveraged Hugging Face’s Transformers library for fine-tuning BERT.The candidate possesses extensive experience working with Python, leveraging it across various projects and for diverse data-related tasks.\n",
       "\n",
       "Their technical proficiency in Python is robust, encompassing a wide array of data manipulation and machine learning libraries such as Pandas, NumPy, Scikit-learn, and TensorFlow. They have also utilized specialized Python libraries like Matplotlib and Seaborn for data visualization, and Transformers, OpenCV, and PyTorch for advanced applications.\n",
       "\n",
       "During an internship at PwC, the candidate applied Python and machine learning techniques to manage the entire lifecycle of a data science project, specifically identifying patterns and developing a decision tree model from a large dataset of incident reports. This involved conducting in-depth exploratory data analysis (EDA) and cleaning datasets using Python.\n",
       "\n",
       "Furthermore, their work with unstructured data heavily relied on Python. An NLP project involved analyzing news articles, requiring text preprocessing, implementation of the LLM BERT, and fine-tuning the model using Python. Similarly, their expertise extends to image classification using CNN and RNN for image captioning, all developed with Python, demonstrating a strong command over handling diverse data types. They have also applied machine learning classifiers in academic projects, such as predicting ICO success, utilizing Python frameworks like TensorFlow, PyTorch, and Scikit-learn to build predictive models and optimize performance.\n",
       "\n",
       "The candidate's skill set also includes advanced NLP concepts in Python, such as Text Preprocessing, Embeddings, Vector Databases (FAISS), BERT (HuggingFace), and Generative AI (LangChain). This comprehensive background underscores their deep engagement with Python for complex analytical and machine learning endeavors.The candidate has a robust background in Python, demonstrating its application across various programming and data-centric tasks.\n",
       "\n",
       "Their contributions and achievements related to Python include:\n",
       "\n",
       "*   **Core Program Implementation:** The candidate has implemented main programs using Python3, including a specific project where Python v3.8 was utilized in an integrated development environment like Spyder. This showcases their ability to design and execute programs in Python.\n",
       "*   **Object-Oriented Programming Proficiency:** They have leveraged Python's object-oriented capabilities, indicating an understanding of creating and utilizing classes and objects for structured code development.\n",
       "*   **Extensive Library Application:** The candidate has proficiently used a wide array of Python libraries to address diverse challenges. This includes:\n",
       "    *   **Data Manipulation and Analysis:** Pandas and NumPy for handling raw data, performing elementary analysis, array manipulation, and computing statistical measures like mean and standard deviation.\n",
       "    *   **Mathematical Operations:** The built-in `math` module for functions such as `pow`, `sqrt`, and `pi`.\n",
       "    *   **Randomization:** The `random` module for generating random numbers.\n",
       "    *   **Data Visualization:** Matplotlib and Seaborn for creating visualizations and presenting complex findings.\n",
       "    *   **Machine Learning:** Scikit-learn for implementing various ML algorithms including Linear Regression, Logistic Regression, KNN, Decision Trees, Naïve Bayes, K-Means, DBSCAN, Random Forest, PCA, and Multi-level Regression.\n",
       "    *   **Deep Learning:** PyTorch, TensorFlow, and OpenCV for developing CNN, RNN, and LSTM models.\n",
       "    *   **Natural Language Processing (NLP):** Transformers, BERT (HuggingFace), and GenAI (LangChain) for tasks such as text preprocessing, embeddings, and working with vector databases (FAISS).\n",
       "*   **Algorithm Development:** They have implemented complex algorithms, such as the Metropolis-Hastings Algorithm, using Python.\n",
       "*   **Data Science Engagement:** The candidate participated in a \"Data Science Project-Based Learning and Internship Program\" specifically utilizing Python programming, demonstrating practical experience in data science workflows.\n",
       "*   **Code Quality and Readability:** They adhere to Python's design philosophy, emphasizing code readability through significant indentation, which aids in maintaining clear and logical code for both small and large-scale projects.\n",
       "*   **Data-Driven Problem Solving:** Their experience has taught them to approach problem-solving with a data-driven mindset, effectively using Python for analysis and visualization to derive insights.The candidate has demonstrated extensive use of Python across a multitude of areas and applications:\n",
       "\n",
       "*   **Data Manipulation and Analysis:** Python, along with libraries like Pandas and NumPy, has been leveraged for managing and analyzing large datasets, including tasks such as data cleaning, transformation, and data matching.\n",
       "*   **Machine Learning and Deep Learning:** The candidate is proficient in employing Python libraries such as Scikit-learn, TensorFlow, and PyTorch for implementing a wide array of machine learning algorithms (e.g., Linear Regression, Logistic Regression, KNN, Decision Trees, Naïve Bayes, K-Means, DBSCAN, Random Forest, PCA, Multi-level Regression) and deep learning models (CNN, RNN, LSTM).\n",
       "*   **Natural Language Processing (NLP):** Python has been instrumental in NLP applications, encompassing text preprocessing, embeddings, utilizing vector databases (FAISS), and working with advanced models like BERT (HuggingFace) and GenAI (LangChain).\n",
       "*   **Data Visualization and Presentation:** The candidate has utilized Python libraries such as Matplotlib and Seaborn to effectively visualize data and present complex findings.\n",
       "*   **General Programming and Project Implementation:** Python 3 has been used for implementing core programs, including the application of object-oriented programming principles and the use of built-in modules like `math` and `random`.\n",
       "*   **Specific Projects and Coursework:** Python was a cornerstone in a Data Science Project-Based Learning and Internship Program, and was specifically applied in a project to estimate public opinion on gun legislation using MRP. Its application is also implied across relevant coursework in areas such as Time Series, Business Analytics, Data Structures & Algorithms, and Statistical Learning.The candidate's professional work involving Python includes:\n",
       "\n",
       "*   **Core Proficiency:** They possess technical proficiency in Python, alongside a wide range of data manipulation and machine learning libraries such as Pandas, NumPy, Scikit-learn, and TensorFlow.\n",
       "*   **Data Handling & Visualization:** They have utilized Python packages like Pandas and NumPy for data cleaning, transformation, and data matching. Data visualization has been performed using Matplotlib in Python to present complex findings.\n",
       "*   **Machine Learning & Deep Learning:** Their skills extend to various Python-based machine learning algorithms and deep learning frameworks, including CNN, RNN, and LSTM, as well as libraries like PyTorch and TensorFlow.\n",
       "*   **Natural Language Processing (NLP):** They have experience with NLP tasks using Python, encompassing text preprocessing, embeddings, vector databases (FAISS), BERT (HuggingFace), and Generative AI (LangChain).\n",
       "*   **Project-Based Application:** Their experience includes a Data Science Project-Based Learning and Internship Program where Python programming was a key component.\n",
       "*   **Specific Project Example:** In a project estimating public opinion on gun legislation, Python packages Pandas and NumPy were used to collect, clean, transform, and match survey and population data, creating input datasets and poststratification frames. Results were then presented using Matplotlib in Python."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d5daa3-9fc3-4b9f-8fec-96f2fb40e453",
   "metadata": {},
   "source": [
    "## Complete Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "606e80d9-e04f-4b48-bf32-87e8bbac72a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_final_human=HumanMessagePromptTemplate.from_template('''\n",
    "You are given information about the candidate that is relevant to the question. Here's the information : {context}\n",
    "Answer this question about the candidate : {question}''')\n",
    "prompt_final=ChatPromptTemplate.from_messages([system_prompt, prompt_final_human])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf4ba55b-3bcf-4158-ba36-a0e239b01ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''final_answer=(\n",
    "    prompt_final\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77a209fe-f1bc-4f85-ad8b-9d9c51fdb5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_answer=(\n",
    "    {'context':(generate_queries\n",
    "               | parallel_rag),\n",
    "     'question':RunnablePassthrough()\n",
    "    }\n",
    "    | prompt_final\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3a4a0c08-169b-472b-a5a2-14768d76c1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=final_answer_t.invoke(my_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1cee177d-57fa-4f5d-a6a8-c4ca0ce1dac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalanswer=final_answer.invoke({'context':answers,'question':my_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fb123d46-4ff1-4538-94f4-02502d769187",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The candidate has engaged in a wide range of work using Python, demonstrating comprehensive experience and expertise. Their work includes:\n",
       "\n",
       "*   **Core Program Implementation:** Implemented the main program for projects like the NAND Trees project using Python3, utilizing its object-oriented capabilities and built-in modules.\n",
       "*   **Data Science & Analysis:**\n",
       "    *   Conducted in-depth analysis of large datasets (e.g., over 50,000 SAP incident reports at PwC) using advanced data analysis techniques.\n",
       "    *   Performed extensive data cleaning, transformation, and data matching using Python packages like Pandas and NumPy for projects such as estimating public opinion on gun legislation.\n",
       "    *   Engaged in exploratory data analysis (EDA) during their PwC internship.\n",
       "*   **Machine Learning & Deep Learning:**\n",
       "    *   Developed and implemented various machine learning models, including a decision tree model for predicting incident resolution likelihood (achieving 97.7% accuracy).\n",
       "    *   Applied deep learning models such as Convolutional Neural Networks (CNN) for image classification and Recurrent Neural Networks (RNN) for image captioning.\n",
       "    *   Utilized and fine-tuned large language models (LLMs) like BERT for text classification and natural language processing tasks, often leveraging Hugging Face's Transformers library.\n",
       "    *   Implemented complex models using Python-based frameworks like TensorFlow, PyTorch, and scikit-learn in research-intensive projects.\n",
       "    *   Has experience with a variety of ML algorithms including Linear Regression, Logistic Regression, KNN, Decision Trees, and Random Forest.\n",
       "*   **Natural Language Processing (NLP):**\n",
       "    *   Collected data through web scraping using Python packages like Selenium and Beautiful Soup.\n",
       "    *   Preprocessed text data for NLP projects, including analyzing news articles.\n",
       "    *   Worked with Text Preprocessing, Embeddings, Vector Databases (FAISS), BERT (HuggingFace), and Generative AI (GenAI) using LangChain.\n",
       "*   **Data Visualization:** Presented complex findings and project results using Matplotlib in Python.\n",
       "*   **Object-Oriented Programming (OOP):** Applied OOP principles in their Python implementations, such as for the NAND Trees project.\n",
       "*   **Project Management & Lifecycle:** Managed the entire lifecycle of a data science project during their internship at PwC, which involved applying Python and machine learning techniques from data acquisition to result communication.\n",
       "\n",
       "They are proficient with a wide array of Python libraries essential for these tasks, including Pandas, NumPy, Scikit-learn, TensorFlow, Matplotlib, Seaborn, Transformers, OpenCV, PyTorch, Selenium, Beautiful Soup, and LangChain."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "362f5c5e-cd83-4f92-a5d5-a46adb04b6ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The candidate has performed a wide range of work in Python, demonstrating extensive proficiency across various domains:\n",
       "\n",
       "1.  **Core Programming and Software Development:**\n",
       "    *   Implemented main programs using Python 3, including specific projects utilizing Python v3.8 in IDEs like Spyder.\n",
       "    *   Leveraged Python's object-oriented programming (OOP) capabilities for structured code development.\n",
       "    *   Adhered to Python's design philosophy, emphasizing code readability through significant indentation.\n",
       "    *   Utilized built-in modules like `math` (for functions like `pow`, `sqrt`, `pi`) and `random` (for generating random numbers).\n",
       "\n",
       "2.  **Data Manipulation, Analysis, and Engineering:**\n",
       "    *   **Data Cleaning, Transformation, and Matching:** Proficiently used Pandas and NumPy for managing large datasets, including tasks like data cleaning, transformation, data matching, and creating input datasets/poststratification frames (e.g., in the Public Opinion project).\n",
       "    *   **Exploratory Data Analysis (EDA):** Conducted in-depth EDA and cleaned datasets, notably during an internship at PwC for incident reports.\n",
       "    *   **Data Pipelines:** Established data pipelines for cleaning, transforming, and integrating data (e.g., in the Quantitative Momentum Investing Model).\n",
       "    *   **Statistical Analysis:** Performed elementary analysis, array manipulation, and computed statistical measures like mean and standard deviation using Pandas and NumPy.\n",
       "    *   **Web Scraping:** Collected data through web scraping using Selenium and Beautiful Soup packages (e.g., for the Russo-Ukrainian War prediction project).\n",
       "\n",
       "3.  **Machine Learning and Deep Learning:**\n",
       "    *   **Algorithm Implementation:** Implemented a wide array of machine learning algorithms using Scikit-learn, including Linear Regression, Logistic Regression, KNN, Decision Trees, Naïve Bayes, K-Means, DBSCAN, Random Forest, PCA, and Multi-level Regression.\n",
       "    *   **Predictive Modeling:** Built predictive models and optimized performance (e.g., predicting ICO success).\n",
       "    *   **Deep Learning Model Construction:** Constructed basic Neural Networks (NN), Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), and Long Short-Term Memory (LSTM) models using TensorFlow, PyTorch, and OpenCV (e.g., for image classification and image captioning using an encoder-decoder architecture).\n",
       "    *   **Algorithm Development:** Implemented complex algorithms like the Metropolis-Hastings Algorithm.\n",
       "\n",
       "4.  **Natural Language Processing (NLP):**\n",
       "    *   **Text Preprocessing:** Performed text preprocessing for analyzing unstructured data like news articles.\n",
       "    *   **Language Models:** Implemented and fine-tuned large language models (LLMs) like BERT using Hugging Face's Transformers library.\n",
       "    *   **Embeddings and Vector Databases:** Worked with advanced NLP concepts such as embeddings and vector databases (FAISS).\n",
       "    *   **Generative AI:** Utilized Generative AI concepts and libraries like LangChain.\n",
       "    *   **Specific Applications:** Applied NLP for analyzing news articles and for image captioning.\n",
       "\n",
       "5.  **Data Visualization and Presentation:**\n",
       "    *   Utilized Matplotlib and Seaborn to create visualizations, present complex findings, and display results (e.g., for the Public Opinion project).\n",
       "\n",
       "6.  **Project Management and Lifecycle:**\n",
       "    *   Managed the entire lifecycle of data science projects, from data collection and cleaning to model development and deployment.\n",
       "    *   Participated in a \"Data Science Project-Based Learning and Internship Program\" specifically utilizing Python.\n",
       "\n",
       "7.  **Specific Project Applications:**\n",
       "    *   **Estimating Public Opinion on Gun Legislation:** Used Pandas, NumPy, and Matplotlib for data collection, cleaning, transformation, matching, and presentation.\n",
       "    *   **Image Classification and Captioning:** Built CNN and RNN models with TensorFlow and PyTorch.\n",
       "    *   **Quantitative Momentum Investing Model:** Established a data pipeline with Pandas and NumPy.\n",
       "    *   **Predicting the Course of the Russo-Ukrainian War:** Involved web scraping with Selenium and Beautiful Soup, data storage as Tensor datasets and PyTorch dataloaders, and fine-tuning BERT with Hugging Face.\n",
       "    *   **PwC Internship:** Applied Python and machine learning to identify patterns and develop a decision tree model from incident reports, involving extensive EDA and data cleaning.\n",
       "\n",
       "In summary, the candidate has leveraged Python as a primary tool for data science, machine learning, deep learning, NLP, data engineering, and general programming, applying it across diverse academic and professional projects."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(finalanswer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b130216f-a500-429e-9f21-76ff4bf3269c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The candidate has performed a variety of work in Python, demonstrating a robust technical proficiency.\n",
       "\n",
       "Their experience includes:\n",
       "*   **Data Manipulation and Analysis:** They have utilized Python packages such as Pandas and NumPy for data cleaning, transformation, and data matching, as evidenced in a project estimating public opinion on gun legislation.\n",
       "*   **Machine Learning and Deep Learning:** The candidate is proficient with Python libraries like Scikit-learn and TensorFlow. Their skills extend to deep learning algorithms including CNN, RNN, and LSTM.\n",
       "*   **Natural Language Processing (NLP):** They have worked with Python-based NLP techniques, including text preprocessing, embeddings, vector databases (FAISS), BERT (HuggingFace), and Generative AI (LangChain).\n",
       "*   **Data Visualization:** The candidate has used Matplotlib in Python to present complex findings, specifically for visualizing results in the public opinion estimation project.\n",
       "*   **General Programming and Project Implementation:** They have implemented main programs in Python3, leveraging its object-oriented capabilities and built-in modules like `math` and `random`.\n",
       "*   **Certifications and Programs:** Their skills were further honed through a Data Science Project-Based Learning and Internship Program that extensively used Python programming.\n",
       "\n",
       "The candidate's listed Python libraries include Pandas, NumPy, Matplotlib, Seaborn, Scikit-learn, Transformers, OpenCV, PyTorch, and TensorFlow, indicating a broad practical application of the language."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3047f351-51af-446a-9b7a-1ea33fa43fff",
   "metadata": {},
   "source": [
    "## Async Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6009502e-eb41-4adb-aca2-517fa1a5a682",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_async= await final_answer.ainvoke(my_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afd68a70-3792-4768-a06b-fa0d3f729ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer=final_answer.invoke(my_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
